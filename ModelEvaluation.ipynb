{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\")\n",
    "#sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "We need to evaluate the performance of our machine learning models because of two main reason. First to be able to tune them deciding which interventions increase their performance and which ones don't. And secondly to have concrete knowlodge on how accurate they are and therefore to what extent can we trust them. \n",
    "\n",
    "The first insight that we have to incorporate into our thinking of model evaluation is that by no means we can evaluate our model with the data that we used for training. Nowadays algorithms are very sophisticated and therefore prone to overfitting. It is therefore necessary to use new data, unseen by model, for its evaluation. \n",
    "\n",
    "There are two main approaches. One, the most obvious, is to divide the data in a training and test set. We train the model with the train set and we use the test set to evaluate it. It is simple and works well if we have lots of data. However, if data is scarce, then we don't have enough diversity in the data and the evaluation could not be very accurate. \n",
    "\n",
    "The second approach tries to solve this problem of evaluation, as accurate as we can, a model with a limited amount of data. As you can imagine, they consist on using sampling techniques with or without repetition in order to try to \"augment\" the amount of data available. \n",
    "\n",
    "Once we have chosen the best hyperparameters and have the model ready for production, we train it with the whole data and put it in operational use. \n",
    "\n",
    "We are going to look at four different techniques that we can use to split our data and create useful estimates of our models:\n",
    "\n",
    "        1) Train and test sets.\n",
    "        2) K-fold Cross-validation.\n",
    "        3) Leave one-out cross-validation.\n",
    "        4) Repeated random test-train splits.\n",
    "\n",
    "Yes, we will use the Pima Indians onset of diabetes dataset. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Pima_indians_cowboy_1889.jpg\">\n",
    "\n",
    "In this exercise we will use one of the traditional Machine Learning dataset, the Pima Indians diabetes dataset.\n",
    "\n",
    "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
    "\n",
    "Content\n",
    "The datasets consists of several medical predictor variables and one target variable, <b>Outcome</b>. Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.\n",
    "<blockquote>\n",
    "        <ul style=\"list-style-type:square;\">\n",
    "            <li>Pregnancies</li> \n",
    "            <li>Glucose</li>\n",
    "            <li>BloodPressure</li>\n",
    "            <li>SkinThickness</li>\n",
    "            <li>Insulin</li>\n",
    "            <li>BMI</li>\n",
    "            <li>DiabetesPedigreeFunction (scores de likelihood of diabetes based on family history)</li>\n",
    "            <li>Age</li>\n",
    "            <li>Outcome</li>\n",
    "        </ul>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>pressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  pressure  skin  insulin   bmi   pedi  age  outcome\n",
       "0            6      148        72    35        0  33.6  0.627   50        1\n",
       "1            1       85        66    29        0  26.6  0.351   31        0\n",
       "2            8      183        64     0        0  23.3  0.672   32        1\n",
       "3            1       89        66    23       94  28.1  0.167   21        0\n",
       "4            0      137        40    35      168  43.1  2.288   33        1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[  6.   , 148.   ,  72.   , ...,  33.6  ,   0.627,  50.   ],\n",
       "       [  1.   ,  85.   ,  66.   , ...,  26.6  ,   0.351,  31.   ],\n",
       "       [  8.   , 183.   ,  64.   , ...,  23.3  ,   0.672,  32.   ],\n",
       "       ...,\n",
       "       [  5.   , 121.   ,  72.   , ...,  26.2  ,   0.245,  30.   ],\n",
       "       [  1.   , 126.   ,  60.   , ...,  30.1  ,   0.349,  47.   ],\n",
       "       [  1.   ,  93.   ,  70.   , ...,  30.4  ,   0.315,  23.   ]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0      1     2     3      4     5      6     7\n",
       "0  6.0  148.0  72.0  35.0    0.0  33.6  0.627  50.0\n",
       "1  1.0   85.0  66.0  29.0    0.0  26.6  0.351  31.0\n",
       "2  8.0  183.0  64.0   0.0    0.0  23.3  0.672  32.0\n",
       "3  1.0   89.0  66.0  23.0   94.0  28.1  0.167  21.0\n",
       "4  0.0  137.0  40.0  35.0  168.0  43.1  2.288  33.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Pima indians dataset and separate input and output components \n",
    "\n",
    "from numpy import set_printoptions\n",
    "set_printoptions(precision=3)\n",
    "\n",
    "filename=\"pima-indians-diabetes.data.csv\"\n",
    "names=[\"pregnancies\", \"glucose\", \"pressure\", \"skin\", \"insulin\", \"bmi\", \"pedi\", \"age\", \"outcome\"]\n",
    "p_indians=pd.read_csv(filename, names=names)\n",
    "p_indians.head()\n",
    "\n",
    "# First we separate into input and output components\n",
    "array=p_indians.values\n",
    "X=array[:,0:8]\n",
    "Y=array[:,8]\n",
    "X\n",
    "pd.DataFrame(X).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Split into Train and Test Sets </h1>\n",
    "\n",
    "A simple idea and also probably the most commonly used approach is to split our data into two sets. Use one for training and the other for testing. Normally a 70% of the data is used for training and 30% for testing, but of course these are arbitrary numbers and anything can be (e.g. 80% - 20% if the dataset is large). \n",
    "\n",
    "The points in favor of this approach is that is simple and fast. It works well when datasets are large but also it is widely used as a first approximation. One important thing that must be taken into account is that the variance of both sets is similar, if not we can encounter unwanted surprises. \n",
    "\n",
    "The downside is that we can have meaninful differences is the differences in variance are high and we that we take an important risk when the amount of data is small. Once the model is in production we may find that its performance has little in common with what we tested because the data that it encounters is really different. \n",
    "\n",
    "The <b> train_test_split </b> module in scikit-learn is the one used for splitting the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>pressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  pressure  skin  insulin   bmi   pedi  age  outcome\n",
       "0            6      148        72    35        0  33.6  0.627   50        1\n",
       "1            1       85        66    29        0  26.6  0.351   31        0\n",
       "2            8      183        64     0        0  23.3  0.672   32        1\n",
       "3            1       89        66    23       94  28.1  0.167   21        0\n",
       "4            0      137        40    35      168  43.1  2.288   33        1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 76.190\n"
     ]
    }
   ],
   "source": [
    "# Split into Train and Test Sets\n",
    "set_printoptions(precision=3)\n",
    "p_indians.head()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "# we need to make it reproducible, so we use a seed for the pseudo-random\n",
    "test_size=0.3\n",
    "seed = 7\n",
    "\n",
    "# the actual split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "# Let's do the log regresssion\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train,Y_train)\n",
    "\n",
    "# Now let's find the accurary with the test split\n",
    "result = model.score(X_test, Y_test)\n",
    "\n",
    "print(f'Accuracy {result*100:5.3f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"red\" size=6>Mission 1</font>\n",
    "\n",
    "a) Change the distribution between Train and Test Sets. How does it affect accurarcy?\n",
    "<br><br>\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Test Size = 0.2\n",
      "Accuracy 78.571\n",
      "########## Test Size = 0.4\n",
      "Accuracy 76.948\n",
      "########## Test Size = 0.6\n",
      "Accuracy 77.657\n",
      "########## Test Size = 0.8\n",
      "Accuracy 77.561\n"
     ]
    }
   ],
   "source": [
    "#a)\n",
    "# USE THE SAME PSEUDO RANDOM SEED AND MANY DIFFERENT TEST SIZES\n",
    "test_size2=0.2\n",
    "test_size4=0.4\n",
    "test_size6=0.6\n",
    "test_size8=0.8\n",
    "seed = 7\n",
    "\n",
    "# the actual splits\n",
    "X_train2, X_test2, Y_train2, Y_test2 = train_test_split(X,Y, test_size=test_size2, random_state=seed)\n",
    "X_train4, X_test4, Y_train4, Y_test4 = train_test_split(X,Y, test_size=test_size4, random_state=seed)\n",
    "X_train6, X_test6, Y_train6, Y_test6 = train_test_split(X,Y, test_size=test_size6, random_state=seed)\n",
    "X_train8, X_test8, Y_train8, Y_test8 = train_test_split(X,Y, test_size=test_size8, random_state=seed)\n",
    "\n",
    "\n",
    "\n",
    "# Let's do the log regresssions\n",
    "model2 = LogisticRegression(solver='liblinear')\n",
    "model4 = LogisticRegression(solver='liblinear')\n",
    "model6 = LogisticRegression(solver='liblinear')\n",
    "model8 = LogisticRegression(solver='liblinear')\n",
    "model2.fit(X_train2,Y_train2)\n",
    "model4.fit(X_train4,Y_train4)\n",
    "model6.fit(X_train6,Y_train6)\n",
    "model8.fit(X_train8,Y_train8)\n",
    "\n",
    "\n",
    "# Now let's find the accurary with the test split\n",
    "result2 = model.score(X_test2, Y_test2)\n",
    "result4 = model.score(X_test4, Y_test4)\n",
    "result6 = model.score(X_test6, Y_test6)\n",
    "result8 = model.score(X_test8, Y_test8)\n",
    "\n",
    "print(\"########## Test Size = 0.2\")\n",
    "print(f'Accuracy {result2*100:5.3f}')\n",
    "\n",
    "print(\"########## Test Size = 0.4\")\n",
    "print(f'Accuracy {result4*100:5.3f}')\n",
    "\n",
    "print(\"########## Test Size = 0.6\")\n",
    "print(f'Accuracy {result6*100:5.3f}')\n",
    "\n",
    "print(\"########## Test Size = 0.8\")\n",
    "print(f'Accuracy {result8*100:5.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=k-fold.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>K-fold Cross-Validation</h1>\n",
    "\n",
    "The objective of k-fold cross-validation is to reduce the variance that we encounter when using the train-test split approach. \n",
    "\n",
    "In this approach the available data is divided into k splits that are called folds (3, 5, 10 are common). We train and test the model k times. Each time we use k-1 folds for training and one fold for testing. Once we finish we use the mean of the evaluation measure together with its standard deviation as performance measure. \n",
    "\n",
    "Obviously the dataset must be large enough to accommodate the process. \n",
    "\n",
    "K-Fold Cross Validation uses the <b>KFold </b> class. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>pressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  pressure  skin  insulin   bmi   pedi  age  outcome\n",
       "0            6      148        72    35        0  33.6  0.627   50        1\n",
       "1            1       85        66    29        0  26.6  0.351   31        0\n",
       "2            8      183        64     0        0  23.3  0.672   32        1\n",
       "3            1       89        66    23       94  28.1  0.167   21        0\n",
       "4            0      137        40    35      168  43.1  2.288   33        1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression, k-fold 10 - Accuracy 76.951% (4.841%)\n"
     ]
    }
   ],
   "source": [
    "# K-fold Cross Validation\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "p_indians.head()\n",
    "\n",
    "# KFold\n",
    "splits=10\n",
    "kfold=KFold(n_splits=splits, random_state=7)\n",
    "\n",
    "#Logistic regression\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Obtain the performance measure - accuracy\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "\n",
    "print(f'Logistic regression, k-fold {splits:d} - Accuracy {results.mean()*100:5.3f}% ({results.std()*100:5.3f}%)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Leave One Out Cross-Validation</h1>\n",
    "\n",
    "What will happen if we take k-fold to the extreme? In this case we will have as many folds as points, so k will be equal to the number of points and the prediction will be done each time for the one point left. \n",
    "\n",
    "This is an effort to make the most reasonable estimate possible given a dataset, it's called leave one out cross validation. \n",
    "\n",
    "Obviously you pay a penalty in terms of computational expense and the standard deviation has more variance than with k-fold. \n",
    "\n",
    "For Leave One Out Cross-Validation you use the <b>LeaveOneOut</b> class. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>pressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  pressure  skin  insulin   bmi   pedi  age  outcome\n",
       "0            6      148        72    35        0  33.6  0.627   50        1\n",
       "1            1       85        66    29        0  26.6  0.351   31        0\n",
       "2            8      183        64     0        0  23.3  0.672   32        1\n",
       "3            1       89        66    23       94  28.1  0.167   21        0\n",
       "4            0      137        40    35      168  43.1  2.288   33        1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression, Leave one out - Accuracy 76.953% (42.113%)\n"
     ]
    }
   ],
   "source": [
    "# Leave one out cross-validation \n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "p_indians.head()\n",
    "\n",
    "# Leave one out cross-validation\n",
    "loo=LeaveOneOut()\n",
    "\n",
    "# Logistic Regression\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "#  performance\n",
    "results = cross_val_score(model, X, Y, cv=loo)\n",
    "\n",
    "print(f'Logistic regression, Leave one out - Accuracy {results.mean()*100:5.3f}% ({results.std()*100:5.3f}%)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Repeated Random Test-Train Splits </h1>\n",
    "\n",
    "Another approach is to apply repeatedly a train-test split. This way takes advantage of the train-test speed and the reduction of variance of cross validation at the same time. \n",
    "\n",
    "A down side of the method is that we are including much of the same data, therefore results even if they look very nice, may not be realistic.\n",
    "\n",
    "For Repeated Random Test-Train Splits you use the <b>ShuffleSplit</b> class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>pressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  pressure  skin  insulin   bmi   pedi  age  outcome\n",
       "0            6      148        72    35        0  33.6  0.627   50        1\n",
       "1            1       85        66    29        0  26.6  0.351   31        0\n",
       "2            8      183        64     0        0  23.3  0.672   32        1\n",
       "3            1       89        66    23       94  28.1  0.167   21        0\n",
       "4            0      137        40    35      168  43.1  2.288   33        1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Regression - Repeated Test-Train 10 - Accuracy 76.970% 1.366%\n"
     ]
    }
   ],
   "source": [
    "# Repeated Random Test-Train Splits\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "p_indians.head()\n",
    "\n",
    "nrepeat=10\n",
    "test_size=0.3\n",
    "seed=7\n",
    "\n",
    "shuffle=ShuffleSplit(n_splits=nrepeat, test_size=test_size, random_state=seed)\n",
    "\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "res = cross_val_score(model, X, Y, cv=shuffle)\n",
    "\n",
    "print(f'Log Regression - Repeated Test-Train {nrepeat:d} - Accuracy {res.mean()*100:5.3f}% {res.std()*100:5.3f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Which one to use and When? </h1>\n",
    "\n",
    "First things first. K-fold is the gold-standard, if you are doing any serious work or presenting results to a digital educated audiende, please use k-fold and you'll avoid problems. \n",
    "\n",
    "Train and Test is ok, and it is used for common quick & dirty work. As you have observed in the exercices if the dataset is moderately large, the differences are small. Certainly you avoid surprises with repeatedly using train-test or much better k-fold and your last model should be evaluated always this way, but train and test split is ok for model selection and hyperparameter tunning. \n",
    "\n",
    "What about the rest? In all these techniques you try to balance accuracy in the estimated performance, evaluation speed and dataset size, they correspond to different bets in this balance. \n",
    "\n",
    "You don't know what to do ... The staple is k-fold with 10-cross-validation, start there. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"red\" size=6>Mission 2</font>\n",
    "\n",
    "a) Using the Shangai Data and log regression for top-10, top-50 and top-100 evaluate the models with train-test split and k-fold-10.\n",
    "<br><br>\n",
    "b) Same for the data of the Times ranking. \n",
    "<br><br>\n",
    "\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>world_rank</th>\n",
       "      <th>university_name</th>\n",
       "      <th>national_rank</th>\n",
       "      <th>total_score</th>\n",
       "      <th>alumni</th>\n",
       "      <th>award</th>\n",
       "      <th>hici</th>\n",
       "      <th>ns</th>\n",
       "      <th>pub</th>\n",
       "      <th>pcp</th>\n",
       "      <th>year</th>\n",
       "      <th>top10</th>\n",
       "      <th>top50</th>\n",
       "      <th>top100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4397</th>\n",
       "      <td>1</td>\n",
       "      <td>Harvard University</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>76.6</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>2</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>2</td>\n",
       "      <td>73.3</td>\n",
       "      <td>40.7</td>\n",
       "      <td>89.6</td>\n",
       "      <td>80.1</td>\n",
       "      <td>70.1</td>\n",
       "      <td>70.6</td>\n",
       "      <td>53.8</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>3</td>\n",
       "      <td>Massachusetts Institute of Technology (MIT)</td>\n",
       "      <td>3</td>\n",
       "      <td>70.4</td>\n",
       "      <td>68.2</td>\n",
       "      <td>80.7</td>\n",
       "      <td>60.6</td>\n",
       "      <td>73.1</td>\n",
       "      <td>61.1</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>4</td>\n",
       "      <td>University of California, Berkeley</td>\n",
       "      <td>4</td>\n",
       "      <td>69.6</td>\n",
       "      <td>65.1</td>\n",
       "      <td>79.4</td>\n",
       "      <td>66.1</td>\n",
       "      <td>65.6</td>\n",
       "      <td>67.9</td>\n",
       "      <td>56.5</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>5</td>\n",
       "      <td>University of Cambridge</td>\n",
       "      <td>1</td>\n",
       "      <td>68.8</td>\n",
       "      <td>77.1</td>\n",
       "      <td>96.6</td>\n",
       "      <td>50.8</td>\n",
       "      <td>55.6</td>\n",
       "      <td>66.4</td>\n",
       "      <td>55.8</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4402</th>\n",
       "      <td>6</td>\n",
       "      <td>Princeton University</td>\n",
       "      <td>5</td>\n",
       "      <td>61.0</td>\n",
       "      <td>53.3</td>\n",
       "      <td>93.4</td>\n",
       "      <td>57.1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>42.4</td>\n",
       "      <td>70.3</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4403</th>\n",
       "      <td>7</td>\n",
       "      <td>California Institute of Technology</td>\n",
       "      <td>6</td>\n",
       "      <td>59.6</td>\n",
       "      <td>49.5</td>\n",
       "      <td>66.7</td>\n",
       "      <td>49.3</td>\n",
       "      <td>56.4</td>\n",
       "      <td>44.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4404</th>\n",
       "      <td>8</td>\n",
       "      <td>Columbia University</td>\n",
       "      <td>7</td>\n",
       "      <td>58.8</td>\n",
       "      <td>63.5</td>\n",
       "      <td>65.9</td>\n",
       "      <td>52.1</td>\n",
       "      <td>51.9</td>\n",
       "      <td>68.8</td>\n",
       "      <td>33.2</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4405</th>\n",
       "      <td>9</td>\n",
       "      <td>University of Chicago</td>\n",
       "      <td>8</td>\n",
       "      <td>57.1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>86.3</td>\n",
       "      <td>49.0</td>\n",
       "      <td>42.9</td>\n",
       "      <td>49.8</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4406</th>\n",
       "      <td>10</td>\n",
       "      <td>University of Oxford</td>\n",
       "      <td>2</td>\n",
       "      <td>56.6</td>\n",
       "      <td>49.7</td>\n",
       "      <td>54.9</td>\n",
       "      <td>52.3</td>\n",
       "      <td>51.9</td>\n",
       "      <td>70.9</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4407</th>\n",
       "      <td>11</td>\n",
       "      <td>Yale University</td>\n",
       "      <td>9</td>\n",
       "      <td>54.5</td>\n",
       "      <td>47.6</td>\n",
       "      <td>50.4</td>\n",
       "      <td>51.0</td>\n",
       "      <td>58.8</td>\n",
       "      <td>63.0</td>\n",
       "      <td>37.8</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4408</th>\n",
       "      <td>12</td>\n",
       "      <td>University of California, Los Angeles</td>\n",
       "      <td>10</td>\n",
       "      <td>50.7</td>\n",
       "      <td>29.5</td>\n",
       "      <td>47.1</td>\n",
       "      <td>52.3</td>\n",
       "      <td>47.2</td>\n",
       "      <td>70.7</td>\n",
       "      <td>31.6</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      world_rank                              university_name national_rank  \\\n",
       "4397           1                           Harvard University             1   \n",
       "4398           2                          Stanford University             2   \n",
       "4399           3  Massachusetts Institute of Technology (MIT)             3   \n",
       "4400           4           University of California, Berkeley             4   \n",
       "4401           5                      University of Cambridge             1   \n",
       "4402           6                         Princeton University             5   \n",
       "4403           7           California Institute of Technology             6   \n",
       "4404           8                          Columbia University             7   \n",
       "4405           9                        University of Chicago             8   \n",
       "4406          10                         University of Oxford             2   \n",
       "4407          11                              Yale University             9   \n",
       "4408          12        University of California, Los Angeles            10   \n",
       "\n",
       "      total_score  alumni  award   hici     ns    pub    pcp  year  top10  \\\n",
       "4397        100.0   100.0  100.0  100.0  100.0  100.0   76.6  2015      1   \n",
       "4398         73.3    40.7   89.6   80.1   70.1   70.6   53.8  2015      1   \n",
       "4399         70.4    68.2   80.7   60.6   73.1   61.1   68.0  2015      1   \n",
       "4400         69.6    65.1   79.4   66.1   65.6   67.9   56.5  2015      1   \n",
       "4401         68.8    77.1   96.6   50.8   55.6   66.4   55.8  2015      1   \n",
       "4402         61.0    53.3   93.4   57.1   43.0   42.4   70.3  2015      1   \n",
       "4403         59.6    49.5   66.7   49.3   56.4   44.0  100.0  2015      1   \n",
       "4404         58.8    63.5   65.9   52.1   51.9   68.8   33.2  2015      1   \n",
       "4405         57.1    59.8   86.3   49.0   42.9   49.8   42.0  2015      1   \n",
       "4406         56.6    49.7   54.9   52.3   51.9   70.9   43.1  2015      1   \n",
       "4407         54.5    47.6   50.4   51.0   58.8   63.0   37.8  2015      0   \n",
       "4408         50.7    29.5   47.1   52.3   47.2   70.7   31.6  2015      0   \n",
       "\n",
       "      top50  top100  \n",
       "4397      1       1  \n",
       "4398      1       1  \n",
       "4399      1       1  \n",
       "4400      1       1  \n",
       "4401      1       1  \n",
       "4402      1       1  \n",
       "4403      1       1  \n",
       "4404      1       1  \n",
       "4405      1       1  \n",
       "4406      1       1  \n",
       "4407      1       1  \n",
       "4408      1       1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################ EVALUATION USING ACCURACY AND TRAINING SPLIT #####################\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY OF 30% TRAINING SPLIT TOP10\n",
      "Accuracy 100.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY OF 30% TRAINING SPLIT TOP 50\n",
      "Accuracy 100.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY OF 30% TRAINING SPLIT TOP 100\n",
      "Accuracy 100.000\n",
      "###################### K-FOLD EVALUATION ######################\n",
      "Logistic regression, k-fold 10 - Accuracy 99.400% (1.281%)\n",
      "Logistic regression, k-fold 10 - Accuracy 99.800% (0.600%)\n",
      "Logistic regression, k-fold 10 - Accuracy 99.200% (1.327%)\n"
     ]
    }
   ],
   "source": [
    "sh = pd.read_csv(\"shanghaiData.csv\")\n",
    "\n",
    "########### CLEAN THE DATASET\n",
    "sh=sh[sh['year']==2015]\n",
    "sh['world_rank'] = sh['world_rank'].str.replace('-', '').astype(int)\n",
    "sh['total_score'].fillna(0,inplace=True)\n",
    "sh['ns'].fillna(0,inplace=True)\n",
    "sh = sh.dropna()\n",
    "\n",
    "\n",
    "########### TESTSIZES AND SEED\n",
    "seed = 7\n",
    "test_size = 0.3\n",
    "\n",
    "\n",
    "############ RECREATE TOP10, TOP50 & TOP100 DATASET\n",
    "n10=10\n",
    "def top10(a):\n",
    "    if a['world_rank']<=n10:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "n50=50\n",
    "def top50(a):\n",
    "    if a['world_rank']<=n50:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "n100=100\n",
    "def top100(a):\n",
    "    if a['world_rank']<=n100:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "sh[\"top10\"]= sh.apply(top10, axis=1).astype(\"int\")\n",
    "sh[\"top50\"]= sh.apply(top50, axis=1).astype(\"int\")\n",
    "sh[\"top100\"]= sh.apply(top100, axis=1).astype(\"int\")\n",
    "sh.head(12)\n",
    "\n",
    "\n",
    "\n",
    "############## SEPARATE INTO INPUT AND OUTPUT COMPONENTS\n",
    "sh_array=sh.values\n",
    "independentsh=sh_array[:,4:11]\n",
    "dependentsh10=sh_array[:,11:12].astype(\"int\")\n",
    "dependentsh50=sh_array[:,12:13].astype(\"int\")\n",
    "dependentsh100=sh_array[:,13].astype(\"int\")\n",
    "\n",
    "print(\"################ EVALUATION USING ACCURACY AND TRAINING SPLIT #####################\")\n",
    "\n",
    "\n",
    "################# MODEL WITH SPLIT=0.3 AND TOP10\n",
    "dependentsh10_train, dependentsh10_test, independentsh_train, independentsh_test  = train_test_split(independentsh, dependentsh10, test_size=test_size, random_state=seed)\n",
    "\n",
    "\n",
    "model2 = LogisticRegression(solver='liblinear')\n",
    "model2.fit(dependentsh10_train, np.ravel(independentsh_train))\n",
    "\n",
    "result2 = model2.score(dependentsh10_test, independentsh_test)\n",
    "print(\"ACCURACY OF 30% TRAINING SPLIT TOP10\")\n",
    "print(f'Accuracy {result2*100:5.3f}')\n",
    "\n",
    "\n",
    "################# MODEL WITH SPLIT=0.3 AND TOP50\n",
    "dependentsh50_train, dependentsh50_test, independentsh_train, independentsh_test  = train_test_split(independentsh, dependentsh50, test_size=test_size, random_state=seed)\n",
    "\n",
    "\n",
    "model3 = LogisticRegression(solver='liblinear')\n",
    "model3.fit(dependentsh50_train, np.ravel(independentsh_train))\n",
    "\n",
    "result3 = model3.score(dependentsh50_test, np.ravel(independentsh_test))\n",
    "print(\"ACCURACY OF 30% TRAINING SPLIT TOP 50\")\n",
    "print(f'Accuracy {result2*100:5.3f}')\n",
    "\n",
    "\n",
    "################# MODEL WITH SPLIT=0.3 AND TOP100\n",
    "dependentsh100_train, dependentsh100_test, independentsh_train, independentsh_test  = train_test_split(independentsh, dependentsh100, test_size=test_size, random_state=seed)\n",
    "\n",
    "\n",
    "model4 = LogisticRegression(solver='liblinear')\n",
    "model4.fit(dependentsh100_train, np.ravel(independentsh_train))\n",
    "\n",
    "result4 = model4.score(dependentsh100_test, np.ravel(independentsh_test))\n",
    "print(\"ACCURACY OF 30% TRAINING SPLIT TOP 100\")\n",
    "print(f'Accuracy {result2*100:5.3f}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"###################### K-FOLD EVALUATION ######################\")\n",
    "\n",
    "#KFold\n",
    "splits= 10\n",
    "kfold= KFold(n_splits=splits, random_state=7, shuffle = True)\n",
    "\n",
    "#Obtain the performance measure - accuracy\n",
    "results10 = cross_val_score(model2, independentsh, np.ravel(dependentsh10), cv=kfold) \n",
    "results50 = cross_val_score(model3, independentsh, np.ravel(dependentsh50), cv=kfold) \n",
    "results100 = cross_val_score(model4, independentsh, np.ravel(dependentsh100), cv=kfold)\n",
    "\n",
    "print(f'Logistic regression, k-fold {splits:d} - Accuracy {results10.mean()*100:5.3f}% ({results10.std()*100:5.3f}%)')\n",
    "print(f'Logistic regression, k-fold {splits:d} - Accuracy {results50.mean()*100:5.3f}% ({results50.std()*100:5.3f}%)')\n",
    "print(f'Logistic regression, k-fold {splits:d} - Accuracy {results100.mean()*100:5.3f}% ({results100.std()*100:5.3f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>world_rank</th>\n",
       "      <th>teaching</th>\n",
       "      <th>international</th>\n",
       "      <th>research</th>\n",
       "      <th>citations</th>\n",
       "      <th>income</th>\n",
       "      <th>num_students</th>\n",
       "      <th>student_staff_ratio</th>\n",
       "      <th>international_students</th>\n",
       "      <th>female_male_ratio</th>\n",
       "      <th>year</th>\n",
       "      <th>top10</th>\n",
       "      <th>top50</th>\n",
       "      <th>top100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>1</td>\n",
       "      <td>92.2</td>\n",
       "      <td>67.0</td>\n",
       "      <td>98.1</td>\n",
       "      <td>99.7</td>\n",
       "      <td>89.1</td>\n",
       "      <td>2243.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>27.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>3</td>\n",
       "      <td>88.6</td>\n",
       "      <td>90.7</td>\n",
       "      <td>97.7</td>\n",
       "      <td>95.5</td>\n",
       "      <td>72.9</td>\n",
       "      <td>19919.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>34.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>4</td>\n",
       "      <td>91.5</td>\n",
       "      <td>69.0</td>\n",
       "      <td>96.7</td>\n",
       "      <td>99.1</td>\n",
       "      <td>63.1</td>\n",
       "      <td>15596.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>22.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>5</td>\n",
       "      <td>89.7</td>\n",
       "      <td>87.8</td>\n",
       "      <td>95.6</td>\n",
       "      <td>95.2</td>\n",
       "      <td>51.1</td>\n",
       "      <td>18812.0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>34.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>6</td>\n",
       "      <td>89.1</td>\n",
       "      <td>84.3</td>\n",
       "      <td>88.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.7</td>\n",
       "      <td>11074.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>7</td>\n",
       "      <td>86.6</td>\n",
       "      <td>61.2</td>\n",
       "      <td>94.7</td>\n",
       "      <td>99.6</td>\n",
       "      <td>82.7</td>\n",
       "      <td>7929.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>27.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>8</td>\n",
       "      <td>84.2</td>\n",
       "      <td>58.5</td>\n",
       "      <td>96.7</td>\n",
       "      <td>99.1</td>\n",
       "      <td>44.8</td>\n",
       "      <td>36186.0</td>\n",
       "      <td>16.4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>9</td>\n",
       "      <td>84.6</td>\n",
       "      <td>92.7</td>\n",
       "      <td>88.3</td>\n",
       "      <td>89.4</td>\n",
       "      <td>72.7</td>\n",
       "      <td>15060.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>51.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1411</th>\n",
       "      <td>9</td>\n",
       "      <td>88.5</td>\n",
       "      <td>59.8</td>\n",
       "      <td>90.8</td>\n",
       "      <td>94.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>11751.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td>11</td>\n",
       "      <td>83.9</td>\n",
       "      <td>65.2</td>\n",
       "      <td>89.9</td>\n",
       "      <td>97.3</td>\n",
       "      <td>36.8</td>\n",
       "      <td>14221.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>21.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>13</td>\n",
       "      <td>78.2</td>\n",
       "      <td>96.6</td>\n",
       "      <td>90.2</td>\n",
       "      <td>83.5</td>\n",
       "      <td>73.2</td>\n",
       "      <td>18178.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>37.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416</th>\n",
       "      <td>15</td>\n",
       "      <td>75.6</td>\n",
       "      <td>59.7</td>\n",
       "      <td>84.2</td>\n",
       "      <td>93.6</td>\n",
       "      <td>100.0</td>\n",
       "      <td>15128.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>23.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      world_rank  teaching  international  research  citations  income  \\\n",
       "1402           1      92.2           67.0      98.1       99.7    89.1   \n",
       "1404           3      88.6           90.7      97.7       95.5    72.9   \n",
       "1405           4      91.5           69.0      96.7       99.1    63.1   \n",
       "1406           5      89.7           87.8      95.6       95.2    51.1   \n",
       "1407           6      89.1           84.3      88.2      100.0    95.7   \n",
       "1408           7      86.6           61.2      94.7       99.6    82.7   \n",
       "1409           8      84.2           58.5      96.7       99.1    44.8   \n",
       "1410           9      84.6           92.7      88.3       89.4    72.7   \n",
       "1411           9      88.5           59.8      90.8       94.0    42.0   \n",
       "1412          11      83.9           65.2      89.9       97.3    36.8   \n",
       "1414          13      78.2           96.6      90.2       83.5    73.2   \n",
       "1416          15      75.6           59.7      84.2       93.6   100.0   \n",
       "\n",
       "      num_students  student_staff_ratio  international_students  \\\n",
       "1402        2243.0                  6.9                    27.0   \n",
       "1404       19919.0                 11.6                    34.0   \n",
       "1405       15596.0                  7.8                    22.0   \n",
       "1406       18812.0                 11.8                    34.0   \n",
       "1407       11074.0                  9.0                    33.0   \n",
       "1408        7929.0                  8.4                    27.0   \n",
       "1409       36186.0                 16.4                    15.0   \n",
       "1410       15060.0                 11.7                    51.0   \n",
       "1411       11751.0                  4.4                    20.0   \n",
       "1412       14221.0                  6.9                    21.0   \n",
       "1414       18178.0                 14.7                    37.0   \n",
       "1416       15128.0                  3.6                    23.0   \n",
       "\n",
       "      female_male_ratio  year  top10  top50  top100  \n",
       "1402               33.0  2015      1      1       1  \n",
       "1404               46.0  2015      1      1       1  \n",
       "1405               42.0  2015      1      1       1  \n",
       "1406               46.0  2015      1      1       1  \n",
       "1407               37.0  2015      1      1       1  \n",
       "1408               45.0  2015      1      1       1  \n",
       "1409               50.0  2015      1      1       1  \n",
       "1410               37.0  2015      1      1       1  \n",
       "1411               50.0  2015      1      1       1  \n",
       "1412               42.0  2015      0      1       1  \n",
       "1414               31.0  2015      0      1       1  \n",
       "1416               50.0  2015      0      1       1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1.000e+00, 9.220e+01, 6.700e+01, ..., 1.000e+00, 1.000e+00,\n",
       "        1.000e+00],\n",
       "       [3.000e+00, 8.860e+01, 9.070e+01, ..., 1.000e+00, 1.000e+00,\n",
       "        1.000e+00],\n",
       "       [4.000e+00, 9.150e+01, 6.900e+01, ..., 1.000e+00, 1.000e+00,\n",
       "        1.000e+00],\n",
       "       ...,\n",
       "       [3.514e+05, 2.850e+01, 3.600e+01, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [3.514e+05, 1.780e+01, 5.010e+01, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [3.514e+05, 1.620e+01, 2.140e+01, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################ EVALUATION USING ACCURACY AND TRAINING SPLIT #####################\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY OF 30% TRAINING SPLIT TOP10\n",
      "Accuracy 100.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY OF 30% TRAINING SPLIT TOP 50\n",
      "Accuracy 98.077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY OF 30% TRAINING SPLIT TOP 100\n",
      "Accuracy 100.000\n",
      "###################### K-FOLD EVALUATION ######################\n",
      "Logistic regression, k-fold 10 - Accuracy 97.672% (3.383%)\n",
      "Logistic regression, k-fold 10 - Accuracy 95.639% (2.990%)\n",
      "Logistic regression, k-fold 10 - Accuracy 88.412% (5.222%)\n"
     ]
    }
   ],
   "source": [
    "################ SAME FOR TIMES RANKING\n",
    "df = pd.read_csv(\"timesData.csv\")\n",
    "\n",
    "########### CLEAN THE DATASET\n",
    "df[\"num_students\"] = df[\"num_students\"].str.replace(',','')\n",
    "df[\"world_rank\"] = df[\"world_rank\"].str.replace('=','')\n",
    "df[\"international_students\"] = df[\"international_students\"].str.replace('%','')\n",
    "df[\"female_male_ratio\"] = df[\"female_male_ratio\"].str[:2]\n",
    "df=df[df['year']==2015]\n",
    "df['world_rank'] = df['world_rank'].str.replace('-', '').astype(int)\n",
    "df = df.drop(columns=\"country\")\n",
    "df = df.drop(columns=\"university_name\")\n",
    "df = df.replace({'-': ''}, regex=True)\n",
    "df = df.drop(columns=\"total_score\")\n",
    "df = df.apply(pd.to_numeric)\n",
    "df = df.dropna()\n",
    "\n",
    "########### TESTSIZES AND SEED\n",
    "seed = 7\n",
    "test_size = 0.3\n",
    "\n",
    "\n",
    "############ RECREATE TOP10, TOP50 & TOP100 DATASET\n",
    "df[\"top10\"]= df.apply(top10, axis=1).astype(\"int\")\n",
    "df[\"top50\"]= df.apply(top50, axis=1).astype(\"int\")\n",
    "df[\"top100\"]= df.apply(top100, axis=1).astype(\"int\")\n",
    "df.head(12)\n",
    "\n",
    "\n",
    "\n",
    "############## SEPARATE INTO INPUT AND OUTPUT COMPONENTS\n",
    "df_array=df.values\n",
    "df_array\n",
    "independent=df_array[:,1:10]\n",
    "dependent10=df_array[:,11:12].astype(\"int\")\n",
    "dependent50=df_array[:,12:13].astype(\"int\")\n",
    "dependent100=df_array[:,13].astype(\"int\")\n",
    "\n",
    "print(\"################ EVALUATION USING ACCURACY AND TRAINING SPLIT #####################\")\n",
    "\n",
    "\n",
    "################# MODEL WITH SPLIT=0.3 AND TOP10\n",
    "dependent10_train, dependent10_test, independent_train, independent_test  = train_test_split(independent, dependent10, test_size=test_size, random_state=seed)\n",
    "\n",
    "\n",
    "model5 = LogisticRegression(solver='liblinear')\n",
    "model5.fit(dependent10_train, np.ravel(independent_train))\n",
    "\n",
    "result5 = model5.score(dependent10_test, independent_test)\n",
    "print(\"ACCURACY OF 30% TRAINING SPLIT TOP10\")\n",
    "print(f'Accuracy {result5*100:5.3f}')\n",
    "\n",
    "\n",
    "################# MODEL WITH SPLIT=0.3 AND TOP50\n",
    "dependent50_train, dependent50_test, independent_train, independent_test  = train_test_split(independent, dependent50, test_size=test_size, random_state=seed)\n",
    "\n",
    "\n",
    "model6 = LogisticRegression(solver='liblinear')\n",
    "model6.fit(dependent50_train, np.ravel(independent_train))\n",
    "\n",
    "result6 = model6.score(dependent50_test, np.ravel(independent_test))\n",
    "print(\"ACCURACY OF 30% TRAINING SPLIT TOP 50\")\n",
    "print(f'Accuracy {result6*100:5.3f}')\n",
    "\n",
    "\n",
    "################# MODEL WITH SPLIT=0.3 AND TOP100\n",
    "dependent100_train, dependent100_test, independent_train, independent_test  = train_test_split(independent, dependent100, test_size=test_size, random_state=seed)\n",
    "\n",
    "\n",
    "model7 = LogisticRegression(solver='liblinear')\n",
    "model7.fit(dependent100_train, np.ravel(independent_train))\n",
    "\n",
    "result7 = model7.score(dependent100_test, np.ravel(independent_test))\n",
    "print(\"ACCURACY OF 30% TRAINING SPLIT TOP 100\")\n",
    "print(f'Accuracy {result2*100:5.3f}')\n",
    "\n",
    "\n",
    "print(\"###################### K-FOLD EVALUATION ######################\")\n",
    "\n",
    "#KFold\n",
    "splits= 10\n",
    "kfold= KFold(n_splits=splits, random_state=7, shuffle = True)\n",
    "\n",
    "#Obtain the performance measure - accuracy\n",
    "ftresults10 = cross_val_score(model5, independent, np.ravel(dependent10), cv=kfold) \n",
    "ftresults50 = cross_val_score(model6, independent, np.ravel(dependent50), cv=kfold) \n",
    "ftresults100 = cross_val_score(model7, independent, np.ravel(dependent100), cv=kfold)\n",
    "\n",
    "print(f'Logistic regression, k-fold {splits:d} - Accuracy {ftresults10.mean()*100:5.3f}% ({ftresults10.std()*100:5.3f}%)')\n",
    "print(f'Logistic regression, k-fold {splits:d} - Accuracy {ftresults50.mean()*100:5.3f}% ({ftresults50.std()*100:5.3f}%)')\n",
    "print(f'Logistic regression, k-fold {splits:d} - Accuracy {ftresults100.mean()*100:5.3f}% ({ftresults100.std()*100:5.3f}%)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
